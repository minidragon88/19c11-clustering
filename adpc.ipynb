{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "adpc.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSj6a1hiTWPC",
        "colab_type": "text"
      },
      "source": [
        "Declaration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAMCm9Y7TaVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import urllib.request\n",
        "from sklearn import mixture\n",
        "from scipy.spatial import distance\n",
        "import math\n",
        "import statistics \n",
        "\n",
        "CUT_OFF_IN_PERCENT = 0.02\n",
        "\n",
        "# Clustering data set\n",
        "# http://cs.joensuu.fi/sipu/datasets/\n",
        "def download_data_set(file_url = 'http://cs.joensuu.fi/sipu/datasets/s1.txt'):\n",
        "  local_filename, headers = urllib.request.urlretrieve(url = file_url)\n",
        "  data = np.loadtxt(local_filename)\n",
        "  dims = data.shape[1]\n",
        "  if dims > 2:\n",
        "    return np.delete(data, 2, 1)\n",
        "  return data\n",
        "\n",
        "def gmm_selection(data_set):\n",
        "  lowest_bic = np.infty\n",
        "  bic = []\n",
        "  n_components_range = range(1, min(10, data_set.shape[0]))\n",
        "  cv_types = ['spherical', 'tied', 'diag', 'full']\n",
        "  for cv_type in cv_types:\n",
        "    for n_components in n_components_range:\n",
        "        # Fit a Gaussian mixture with EM\n",
        "        gmm = mixture.GaussianMixture(n_components=n_components, covariance_type=cv_type)\n",
        "        gmm.fit(data_set)\n",
        "        bic.append(gmm.bic(data_set))\n",
        "        if bic[-1] < lowest_bic:\n",
        "            lowest_bic = bic[-1]\n",
        "            best_gmm = gmm\n",
        "  # print(best_gmm)\n",
        "  return best_gmm\n",
        "\n",
        "# Get all euclid distance between points with keeping their respective order\n",
        "def get_all_distances(data_set):\n",
        "  arr_leng = data_set.shape[0]\n",
        "  all_distances = []\n",
        "  for i in range(arr_leng):\n",
        "    current_point_distances = []\n",
        "    for j in range(arr_leng):\n",
        "      if i == j:\n",
        "        continue\n",
        "      current_point_distances.append(distance.euclidean(data_set[i], data_set[j]))\n",
        "    all_distances.append(current_point_distances)\n",
        "  return np.array(all_distances)\n",
        "\n",
        "def get_cut_off_distance(distances_data):\n",
        "  arr_leng, dims = distances_data.shape\n",
        "  # Get number of neighbors\n",
        "  number_of_items = math.ceil(CUT_OFF_IN_PERCENT * dims)\n",
        "  all_distances = []\n",
        "  for i in range(arr_leng):\n",
        "    point_distance = np.array(distances_data[i])\n",
        "    # Get number_of_items smallest distance\n",
        "    point_distance = np.partition(point_distance,number_of_items)[:number_of_items]\n",
        "    for dist in point_distance:\n",
        "      all_distances.append(dist)\n",
        "  return statistics.mean(all_distances) \n",
        "\n",
        "def get_density_of_point(point_distance, cut_off_distance):\n",
        "  arr_leng = len(point_distance)\n",
        "  result = 0\n",
        "  for i in range(arr_leng):\n",
        "    if point_distance[i] < cut_off_distance:\n",
        "      result += 1\n",
        "  return result\n",
        "\n",
        "def get_densities(distances_data, cut_off_distance):\n",
        "  arr_leng = distances_data.shape[0]\n",
        "  result = []\n",
        "  for i in range(arr_leng):\n",
        "    result.append(get_density_of_point(distances_data[i], cut_off_distance))\n",
        "  return np.array(result)\n",
        "\n",
        "def get_distribution(data_set):\n",
        "  unique, counts = np.unique(data_set, return_counts=True)\n",
        "  arr_leng = unique.shape[0]\n",
        "  result = []\n",
        "  for i in range(arr_leng):\n",
        "    result.append([unique[i], counts[i]])\n",
        "  return np.array(result)\n",
        "\n",
        "def get_density_groups(densities, densities_distribution, groups):\n",
        "  result = []\n",
        "  for i in range(len(densities)):\n",
        "    current_density = densities[i]\n",
        "    for j in range(len(densities_distribution)):\n",
        "      if current_density == densities_distribution[j][0]:\n",
        "        result.append(groups[j])\n",
        "        break\n",
        "  return np.array(result)\n",
        "  \n",
        "def get_neighbors(all_distances, current_point_index, cut_off_distance):\n",
        "  neighbor_indexes = []\n",
        "  neighbor_dinstances = []\n",
        "  point_distances = all_distances[current_point_index]\n",
        "  for i in range(len(point_distances)):\n",
        "    if point_distances[i] < cut_off_distance:\n",
        "      if i < current_point_index:\n",
        "        neighbor_indexes.append(i)\n",
        "      else:\n",
        "        neighbor_indexes.append(i + 1)\n",
        "      neighbor_dinstances.append(point_distances[i])\n",
        "  return (neighbor_indexes, neighbor_dinstances)\n",
        "\n",
        "def get_index_before_sort(sorted_index, argsort_arr):\n",
        "  return argsort_arr[sorted_index]\n",
        "\n",
        "def get_respective_index(index, argsort_arr):\n",
        "  return argsort_arr[index]\n",
        "\n",
        "def get_minimum_gaussian_groups(densities_distribution, groups):\n",
        "  results = []\n",
        "  for i in range(len(np.unique(groups))):\n",
        "    results.append(0)\n",
        "  for i in range(len(densities_distribution)):\n",
        "    # print(str(groups[i]) + \"\" + str(densities_distribution[i]))\n",
        "    group = groups[i]\n",
        "    results[group] += densities_distribution[i][1]\n",
        "  return np.where(results == min(results))[0]"
      ],
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgRv9qL0vGxU",
        "colab_type": "text"
      },
      "source": [
        "Download data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxJuyksbvIQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download data set\n",
        "raw_data_set = download_data_set('http://cs.joensuu.fi/sipu/datasets/R15.txt')"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-MxoK4GUGOD",
        "colab_type": "text"
      },
      "source": [
        "Download data, calculate all relevant variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld46kkgKUGeW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate all distances\n",
        "all_distances = get_all_distances(raw_data_set)\n",
        "\n",
        "# get cut off distance\n",
        "cut_off_distance = get_cut_off_distance(all_distances)\n",
        "\n",
        "# calculate densitive base on cut off distance\n",
        "densities = get_densities(all_distances, cut_off_distance)\n",
        "\n",
        "# form the distribution to perform gmm selection\n",
        "densities_distribution = get_distribution(densities)\n",
        "\n",
        "# get gmm models\n",
        "gmm_model = gmm_selection(densities_distribution)\n",
        "\n",
        "# get respective groups\n",
        "groups = gmm_model.predict(densities_distribution)\n",
        "\n",
        "# get a respective vector with original densities to represent the desitive of respective point\n",
        "densities_groups = get_density_groups(densities, densities_distribution, groups)\n",
        "\n",
        "# Referenced of the original array for futher classification point\n",
        "densities_argsort = densities.argsort()[::-1]\n",
        "\n",
        "# Copy to avoid sam referenced then sort in decending order\n",
        "sorted_densities = np.array(densities)\n",
        "sorted_densities.sort()\n",
        "sorted_densities = sorted_densities[::-1]\n",
        "\n",
        "# Calculate minimum gauss\n",
        "minimum_gaussian_groups = get_minimum_gaussian_groups(densities_distribution, groups)"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ3JN2Dy0OsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(all_distances[0])\n",
        "print(get_neighbors(all_distances, 0, cut_off_distance))\n",
        "# for i in range(600):\n",
        "  # print(len(get_neighbors(all_distances, i, cut_off_distance)))\n",
        "print(raw_data_set[0])\n",
        "print(densities_distribution)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4_x7jhM6PNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqFzqYPN6QUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c317d39a-81f0-4b94-fe0a-e01f3b81ca22"
      },
      "source": [
        "# sorted_densities cluster_centers = np.append(cluster_centers, 1)\n",
        "data_set_length = len(raw_data_set)\n",
        "cluster_centers = []\n",
        "cluster_centers_label = []\n",
        "labels = np.zeros((data_set_length,), dtype=np.int)\n",
        "current_label = 0\n",
        "# for loop in range(data_set_length):\n",
        "for loop in range(data_set_length):\n",
        "  index_in_raw_data = get_respective_index(loop, densities_argsort)\n",
        "  neighbor_indexes, neighbor_distances = get_neighbors(all_distances, index_in_raw_data, cut_off_distance)\n",
        "  neighbors_has_clustered = []\n",
        "  neighbors_has_clustered_distance = []\n",
        "  neighbors_density_group = []\n",
        "  for n_count in range(len(neighbor_indexes)):\n",
        "    neighbor_index_in_sorted = get_respective_index(neighbor_indexes[n_count], densities_argsort)\n",
        "    if labels[neighbor_index_in_sorted] != 0:\n",
        "      neighbors_has_clustered.append(neighbor_index_in_sorted)\n",
        "      neighbors_has_clustered_distance.append(neighbor_distances[n_count])\n",
        "      neighbors_density_group.append(densities_groups[neighbor_indexes[n_count]])\n",
        "  # print(neighbors_density_group)\n",
        "  if len(neighbors_has_clustered) > 0:\n",
        "    if len(neighbors_has_clustered) == 1:\n",
        "      labels[loop] = labels[get_respective_index(neighbors_has_clustered[0], densities_argsort)]\n",
        "    elif len(neighbors_has_clustered) > 1:\n",
        "      continue\n",
        "    else:\n",
        "      # If there are no comparative neighbor's cluster center with the same gaussian group with current point\n",
        "      # Then get the cluster center of nearest neighbors and belong to that clusters\n",
        "      decided_cluster = neighbors_has_clustered[neighbors_has_clustered_distance.index(min(neighbors_has_clustered_distance))]\n",
        "      labels[loop] = labels[decided_cluster]\n",
        "  elif (not densities_groups[index_in_raw_data] in minimum_gaussian_groups) and sorted_densities[loop] > 0:\n",
        "    # No neighbor then promote to cluster center\n",
        "    cluster_centers.append(loop)\n",
        "    current_label += 1\n",
        "    # Keep respective cluster label with cluster centers\n",
        "    cluster_centers_label.append(current_label)\n",
        "    labels[loop] = current_label\n",
        "  else:\n",
        "    # Outlier point, ignore\n",
        "    continue\n",
        "\n",
        "print(len(labels))\n",
        "print(len(cluster_centers))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n",
            "188\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}